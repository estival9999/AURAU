"""
Agente Orquestrador - O "maestro" do sistema AURALIS.
Interpreta inten√ß√µes, direciona para agentes especializados e coordena respostas.
"""

from typing import Dict, List, Any, Optional, Tuple
import json
import os
from enum import Enum

# Importar classe base apropriada
if os.getenv("OPENAI_API_KEY"):
    from .agente_base import AgenteBase
else:
    from .agente_base_simulado import AgenteBaseSimulado as AgenteBase

# Importar o novo sistema de templates
from .prompt_template import PromptTemplate, TomResposta


class TipoIntencao(Enum):
    """Tipos de inten√ß√£o que o orquestrador pode identificar.

    Cada tipo direciona para um agente especializado diferente.
    """
    CONSULTA = "CONSULTA"      # Busca de informa√ß√µes
    BRAINSTORM = "BRAINSTORM"  # Gera√ß√£o de ideias
    ANALISE = "ANALISE"        # An√°lise de dados
    GERAL = "GERAL"            # Consultas gerais
    MULTIPLA = "MULTIPLA"      # M√∫ltiplas inten√ß√µes


class AgenteOrquestrador(AgenteBase):
    """
    Agente respons√°vel por orquestrar o sistema AURALIS.

    Principais responsabilidades:
    - Interpretar inten√ß√µes do usu√°rio
    - Direcionar para agentes especializados
    - Coordenar respostas m√∫ltiplas
    - Manter contexto geral da conversa
    """

    def __init__(self):
        super().__init__(
            nome="Orquestrador AURALIS",
            descricao="Agente maestro que coordena e direciona as intera√ß√µes no sistema"
        )

        # ===== CONFIGURA√á√ÉO DO TEMPLATE =====
        # Usa o novo sistema de templates padronizados
        self.config_prompt = PromptTemplate.criar_config_orquestrador()

        # ===== MAPA DE AGENTES ESPECIALIZADOS =====
        # Mapeia cada tipo de inten√ß√£o para o nome do agente respons√°vel
        self.mapa_agentes = {
            TipoIntencao.CONSULTA: "Consultor Inteligente AURALIS",
            TipoIntencao.BRAINSTORM: "Agente Criativo AURALIS",
            TipoIntencao.ANALISE: "Analista AURALIS"
        }

        # ===== REFER√äNCIAS AOS AGENTES =====
        # Refer√™ncias diretas aos agentes especializados
        # Ser√£o definidas pelo sistema atrav√©s do m√©todo definir_agentes()
        self.agente_consulta = None
        self.agente_brainstorm = None
        self.agente_analise = None

        # ===== PALAVRAS-CHAVE PARA IDENTIFICA√á√ÉO =====
        # Dicion√°rio expandido com sin√¥nimos e varia√ß√µes
        self.palavras_chave = {
            TipoIntencao.CONSULTA: [
                # Verbos de busca
                "buscar", "encontrar", "procurar", "localizar", "pesquisar", "consultar",
                "verificar", "checar", "conferir", "identificar", "descobrir",
                # Pronomes interrogativos
                "quando", "onde", "quem", "qual", "quais", "quanto", "como", "porque",
                # Substantivos relacionados
                "reuni√£o", "reuni√µes", "meeting", "documento", "documentos", "arquivo",
                "hist√≥rico", "informa√ß√£o", "informa√ß√µes", "dado", "dados", "registro",
                # A√ß√µes de visualiza√ß√£o
                "listar", "mostrar", "exibir", "apresentar", "ver", "visualizar",
                # Contexto temporal
                "√∫ltima", "√∫ltimo", "anterior", "passada", "recente", "hoje", "ontem",
                "semana", "m√™s", "participou", "participaram", "decidiu", "decidido",
                # Termos temporais espec√≠ficos
                "primeira", "segunda", "terceira", "pen√∫ltima", "√∫ltima", 
                "mais recente", "mais antiga"
            ],
            TipoIntencao.BRAINSTORM: [
                # Substantivos criativos
                "ideia", "ideias", "sugest√£o", "sugest√µes", "proposta", "propostas",
                "solu√ß√£o", "solu√ß√µes", "alternativa", "alternativas", "op√ß√£o", "op√ß√µes",
                # Verbos de cria√ß√£o
                "criar", "gerar", "produzir", "desenvolver", "elaborar", "pensar",
                "imaginar", "inovar", "inventar", "conceber", "formular",
                # Termos de melhoria
                "melhorar", "aprimorar", "otimizar", "aperfei√ßoar", "evoluir",
                "transformar", "revolucionar", "mudar", "modificar",
                # Termos expl√≠citos
                "brainstorm", "brainstorming", "criativo", "criatividade", "inova√ß√£o",
                "inovador", "fora da caixa", "diferente", "novo", "original"
            ],
            TipoIntencao.ANALISE: [
                # Verbos anal√≠ticos
                "analisar", "examinar", "investigar", "estudar", "avaliar", "revisar",
                "comparar", "contrastar", "correlacionar", "diagnosticar",
                # Substantivos anal√≠ticos
                "an√°lise", "tend√™ncia", "tend√™ncias", "padr√£o", "padr√µes", "comportamento",
                "estat√≠stica", "estat√≠sticas", "m√©trica", "m√©tricas", "indicador",
                "indicadores", "kpi", "dashboard", "relat√≥rio", "gr√°fico",
                # Termos de insights
                "insight", "insights", "conclus√£o", "conclus√µes", "descoberta",
                "observa√ß√£o", "interpreta√ß√£o", "entendimento", "compreens√£o"
            ]
        }

        # ===== CONFIGURA√á√ïES DO MODELO =====
        # Usa configura√ß√µes do template
        self.temperatura = self.config_prompt.temperatura
        
        # ===== HIST√ìRICO DA CONVERSA =====
        # Mant√©m hist√≥rico da conversa atual para contexto
        self.historico_conversa_atual = []
        
        # ===== CONTADOR DE MENSAGENS SEM CONTE√öDO =====
        self.mensagens_vazias = 0

    def get_prompt_sistema(self) -> str:
        """
        Define o prompt do sistema para o agente orquestrador.

        Returns:
            str: Prompt do sistema usando o template padronizado
        """
        # Usa o novo sistema de templates com contexto atual
        return PromptTemplate.gerar_prompt_contextualizado(
            self.config_prompt,
            self.contexto_atual
        )

    def identificar_intencao(self, mensagem: str) -> Tuple[TipoIntencao, float]:
        """
        Identifica a inten√ß√£o principal da mensagem do usu√°rio.

        Args:
            mensagem: Mensagem do usu√°rio

        Returns:
            Tuple[TipoIntencao, float]: Tipo de inten√ß√£o e score de confian√ßa
        """
        mensagem_lower = mensagem.lower()

        # ===== C√ÅLCULO DE SCORES =====
        # Calcula pontos para cada tipo de inten√ß√£o baseado nas palavras-chave encontradas
        scores = {}

        for tipo_intencao, palavras in self.palavras_chave.items():
            # Conta quantas palavras-chave est√£o presentes na mensagem
            score = sum(1 for palavra in palavras if palavra in mensagem_lower)
            scores[tipo_intencao] = score

        # Identificar inten√ß√£o com maior score
        max_score = max(scores.values())

        # Se nenhuma palavra-chave foi encontrada, classifica como consulta geral
        if max_score == 0:
            return TipoIntencao.GERAL, 0.5

        # ===== DETEC√á√ÉO DE M√öLTIPLAS INTEN√á√ïES =====
        # Verifica se h√° m√∫ltiplas inten√ß√µes com scores pr√≥ximos (70% do m√°ximo)
        intencoes_altas = [t for t, s in scores.items() if s >= max_score * 0.7 and s > 0]

        if len(intencoes_altas) > 1:
            return TipoIntencao.MULTIPLA, 0.8

        # Retornar a inten√ß√£o com maior score
        intencao_principal = max(scores, key=scores.get)
        # Normaliza a confian√ßa entre 0 e 1 (m√°ximo de 5 palavras-chave)
        confianca = min(scores[intencao_principal] / 5.0, 1.0)

        return intencao_principal, confianca

    def identificar_multiplas_intencoes(self, mensagem: str) -> List[TipoIntencao]:
        """
        Identifica m√∫ltiplas inten√ß√µes em uma mensagem.

        Args:
            mensagem: Mensagem do usu√°rio

        Returns:
            List[TipoIntencao]: Lista de inten√ß√µes identificadas
        """
        mensagem_lower = mensagem.lower()
        intencoes_encontradas = []

        for tipo_intencao, palavras in self.palavras_chave.items():
            if any(palavra in mensagem_lower for palavra in palavras):
                intencoes_encontradas.append(tipo_intencao)

        return intencoes_encontradas if intencoes_encontradas else [TipoIntencao.GERAL]

    def _verificar_casos_especiais(self, mensagem: str) -> Optional[str]:
        """
        Verifica casos especiais e erros comuns antes do processamento.

        Args:
            mensagem: Mensagem do usu√°rio

        Returns:
            Optional[str]: Resposta de erro se aplic√°vel, None caso contr√°rio
        """
        # ===== ENTRADA VAZIA =====
        if not mensagem or not mensagem.strip():
            self.mensagens_vazias += 1
            if self.mensagens_vazias == 1:
                return "Como posso ajudar? ü§ñ"
            else:
                return "Digite algo para eu poder ajudar."

        # Reset contador se mensagem n√£o √© vazia
        self.mensagens_vazias = 0

        # ===== ENTRADA MUITO CURTA (poss√≠vel comando incompleto) =====
        mensagem_limpa = mensagem.strip().lower()
        if len(mensagem_limpa) < 3:
            return "Mensagem muito curta. Pode elaborar?"

        # ===== ENTRADA MUITO LONGA =====
        if len(mensagem) > 1000:
            return "Mensagem muito longa. Tente ser mais direto."

        # ===== COMANDOS DE AJUDA =====
        if mensagem_limpa in ["ajuda", "help", "?", "o que voc√™ faz", "o que voce faz", "comandos"]:
            return self._gerar_mensagem_ajuda()

        # ===== SAUDA√á√ïES =====
        saudacoes = ["oi", "ol√°", "ola", "bom dia", "boa tarde", "boa noite", "hey", "ei"]
        if mensagem_limpa in saudacoes:
            # Resposta concisa e precisa
            return "Ol√°! Como posso ajudar? ü§ñüîç"

        return None  # Nenhum caso especial detectado

    def _gerar_mensagem_ajuda(self) -> str:
        """
        Gera mensagem de ajuda concisa.

        Returns:
            str: Mensagem de ajuda formatada
        """
        return """**Posso ajudar com:**
‚Ä¢ Buscar reuni√µes e documentos
‚Ä¢ Gerar ideias e sugest√µes
‚Ä¢ Analisar dados e tend√™ncias

**Exemplos:**
"√öltima reuni√£o sobre vendas"
"Ideias para melhorar produtividade"
"An√°lise das reuni√µes do m√™s"
"""

    def processar_mensagem(self, mensagem: str, contexto: Dict[str, Any] = None) -> str:
        """
        Processa a mensagem do usu√°rio e orquestra a resposta.

        Args:
            mensagem: Mensagem do usu√°rio
            contexto: Contexto adicional

        Returns:
            str: Resposta orquestrada
        """
        # Atualizar contexto
        if contexto:
            self.atualizar_contexto(contexto)

        # ===== ADICIONAR AO HIST√ìRICO DA CONVERSA =====
        self.historico_conversa_atual.append({
            "role": "user",
            "content": mensagem,
            "timestamp": self.contexto_atual.get("timestamp", "")
        })

        # ===== VALIDA√á√ïES E CASOS ESPECIAIS =====
        # Verifica casos de erro antes de processar
        resposta_erro = self._verificar_casos_especiais(mensagem)
        if resposta_erro:
            return resposta_erro

        # Identificar inten√ß√£o
        intencao, confianca = self.identificar_intencao(mensagem)

        # Log para depura√ß√£o - mostra a inten√ß√£o identificada
        print(f"[ORQUESTRADOR] Inten√ß√£o identificada: {intencao.value} (confian√ßa: {confianca:.2f})")

        # ===== PROCESSAMENTO BASEADO NA INTEN√á√ÉO =====
        if intencao == TipoIntencao.MULTIPLA:
            # Identifica e processa cada inten√ß√£o separadamente
            intencoes = self.identificar_multiplas_intencoes(mensagem)
            resposta = self._processar_multiplas_intencoes(mensagem, intencoes, contexto)

        elif intencao == TipoIntencao.GERAL:
            # Responder diretamente
            resposta = self._processar_consulta_geral(mensagem, contexto)

        else:
            # Delegar para agente espec√≠fico
            resposta = self._delegar_para_agente(mensagem, intencao, contexto)

        # Adicionar resposta ao hist√≥rico
        self.historico_conversa_atual.append({
            "role": "assistant",
            "content": resposta,
            "timestamp": self.contexto_atual.get("timestamp", "")
        })
        
        # Manter apenas √∫ltimas 10 mensagens no hist√≥rico
        if len(self.historico_conversa_atual) > 10:
            self.historico_conversa_atual = self.historico_conversa_atual[-10:]

        # Adicionar ao hist√≥rico permanente
        self.adicionar_ao_historico(mensagem, resposta)

        return resposta

    def _processar_multiplas_intencoes(self, mensagem: str, intencoes: List[TipoIntencao],
                                      contexto: Dict[str, Any]) -> str:
        """
        Processa m√∫ltiplas inten√ß√µes coordenando v√°rios agentes.

        Args:
            mensagem: Mensagem original
            intencoes: Lista de inten√ß√µes identificadas
            contexto: Contexto da conversa

        Returns:
            str: Resposta consolidada
        """
        respostas = []

        # Mensagem introdut√≥ria concisa
        respostas.append("Vou abordar cada parte:\n")

        # ===== PROCESSAMENTO DE CADA INTEN√á√ÉO =====
        for i, intencao in enumerate(intencoes, 1):
            # Pula inten√ß√µes gerais (j√° processadas)
            if intencao == TipoIntencao.GERAL:
                continue

            # Adiciona subt√≠tulo formatado para cada se√ß√£o
            subtitulo = f"\n**{self._get_titulo_intencao(intencao)}:**"
            respostas.append(subtitulo)

            # Delega para o agente especializado apropriado
            resposta_agente = self._delegar_para_agente(mensagem, intencao, contexto)
            respostas.append(resposta_agente)

        return "\n".join(respostas)

    def _delegar_para_agente(self, mensagem: str, intencao: TipoIntencao,
                            contexto: Dict[str, Any]) -> str:
        """
        Delega a mensagem para o agente especializado apropriado.

        Args:
            mensagem: Mensagem para processar
            intencao: Tipo de inten√ß√£o identificada
            contexto: Contexto da conversa

        Returns:
            str: Resposta do agente especializado
        """
        # Adicionar hist√≥rico da conversa ao contexto
        contexto_completo = contexto.copy() if contexto else {}
        contexto_completo["historico_conversa"] = self.historico_conversa_atual
        
        # ===== DELEGA√á√ÉO PARA AGENTES ESPECIALIZADOS =====
        # Verifica se temos refer√™ncia direta ao agente apropriado
        if intencao == TipoIntencao.CONSULTA and self.agente_consulta:
            return self.agente_consulta.processar_mensagem(mensagem, contexto_completo)

        elif intencao == TipoIntencao.BRAINSTORM and self.agente_brainstorm:
            return self.agente_brainstorm.processar_mensagem(mensagem, contexto_completo)

        elif intencao == TipoIntencao.ANALISE and self.agente_analise:
            # Se n√£o temos agente de an√°lise espec√≠fico, usa o de consulta
            agente = self.agente_analise or self.agente_consulta
            if agente:
                return agente.processar_mensagem(mensagem, contexto_completo)

        # Fallback: se n√£o h√° agente dispon√≠vel, processa localmente
        return self._processar_localmente(mensagem, intencao, contexto_completo)

    def _processar_localmente(self, mensagem: str, intencao: TipoIntencao,
                             contexto: Dict[str, Any]) -> str:
        """
        Processa a mensagem localmente quando n√£o h√° agente especializado dispon√≠vel.

        Args:
            mensagem: Mensagem para processar
            intencao: Tipo de inten√ß√£o
            contexto: Contexto da conversa

        Returns:
            str: Resposta processada localmente
        """
        # Prepara prompt espec√≠fico para processamento local
        prompt = f"""Como Orquestrador do AURALIS, processe esta solicita√ß√£o de tipo {intencao.value}:

Mensagem do usu√°rio: {mensagem}

Contexto dispon√≠vel:
{self.formatar_contexto(contexto)}

Hist√≥rico recente:
{self._formatar_historico_para_prompt()}

Forne√ßa uma resposta apropriada, clara e concisa."""

        # Chama o modelo de linguagem para processar a solicita√ß√£o
        resposta = self.chamar_llm(prompt)

        return resposta

    def _processar_consulta_geral(self, mensagem: str, contexto: Dict[str, Any]) -> str:
        """
        Processa consultas gerais que o orquestrador pode responder diretamente.

        Args:
            mensagem: Mensagem do usu√°rio
            contexto: Contexto da conversa

        Returns:
            str: Resposta direta
        """
        prompt = f"""Como Orquestrador do AURALIS, responda diretamente esta consulta geral:

Mensagem: {mensagem}

Contexto:
{self.formatar_contexto(contexto)}

Hist√≥rico recente:
{self._formatar_historico_para_prompt()}

Seja claro, conciso e profissional. Responda em no m√°ximo 3 linhas."""

        return self.chamar_llm(prompt)

    def _get_titulo_intencao(self, intencao: TipoIntencao) -> str:
        """
        Retorna um t√≠tulo amig√°vel para cada tipo de inten√ß√£o.

        Args:
            intencao: Tipo de inten√ß√£o

        Returns:
            str: T√≠tulo formatado
        """
        titulos = {
            TipoIntencao.CONSULTA: "Busca",
            TipoIntencao.BRAINSTORM: "Ideias",
            TipoIntencao.ANALISE: "An√°lise",
            TipoIntencao.GERAL: "Informa√ß√£o"
        }
        return titulos.get(intencao, "Processamento")

    def _formatar_historico_para_prompt(self) -> str:
        """
        Formata o hist√≥rico da conversa para incluir no prompt.
        
        Returns:
            str: Hist√≥rico formatado
        """
        if not self.historico_conversa_atual:
            return "Nenhum hist√≥rico dispon√≠vel"
        
        # Pegar apenas as √∫ltimas 5 mensagens
        historico_recente = self.historico_conversa_atual[-5:]
        
        formatted = []
        for msg in historico_recente:
            role = "Usu√°rio" if msg["role"] == "user" else "Assistente"
            content = msg["content"][:100] + "..." if len(msg["content"]) > 100 else msg["content"]
            formatted.append(f"{role}: {content}")
        
        return "\n".join(formatted)

    def definir_agentes(self, agente_consulta=None, agente_brainstorm=None, agente_analise=None):
        """
        Define as refer√™ncias diretas aos agentes especializados.

        Args:
            agente_consulta: Inst√¢ncia do agente de consulta
            agente_brainstorm: Inst√¢ncia do agente de brainstorm
            agente_analise: Inst√¢ncia do agente de an√°lise
        """
        if agente_consulta:
            self.agente_consulta = agente_consulta
        if agente_brainstorm:
            self.agente_brainstorm = agente_brainstorm
        if agente_analise:
            self.agente_analise = agente_analise

    def gerar_resumo_executivo(self, topico: str, informacoes: Dict[str, Any]) -> str:
        """
        Gera um resumo executivo consolidando informa√ß√µes de m√∫ltiplas fontes.

        Args:
            topico: T√≥pico do resumo
            informacoes: Dicion√°rio com informa√ß√µes de diferentes agentes

        Returns:
            str: Resumo executivo formatado
        """
        prompt = f"""Gere um resumo executivo profissional sobre: {topico}

Informa√ß√µes dispon√≠veis:
{json.dumps(informacoes, ensure_ascii=False, indent=2)}

O resumo deve incluir:
1. Vis√£o geral (2-3 linhas)
2. Principais pontos identificados
3. Recomenda√ß√µes baseadas nas an√°lises
4. Pr√≥ximos passos sugeridos

Formato profissional e conciso."""

        return self.chamar_llm(prompt)

    def coordenar_analise_completa(self, topico: str) -> Dict[str, Any]:
        """
        Coordena uma an√°lise completa usando todos os agentes dispon√≠veis.

        Args:
            topico: T√≥pico para an√°lise completa

        Returns:
            Dict: Resultados consolidados de todos os agentes
        """
        resultados = {
            "topico": topico,
            "timestamp": self.contexto_atual.get("timestamp", ""),
            "analises": {}
        }

        # ===== FASE 1: CONSULTA DE INFORMA√á√ïES =====
        # Busca todas as informa√ß√µes existentes sobre o t√≥pico
        if self.agente_consulta:
            resultados["analises"]["informacoes"] = self.agente_consulta.processar_mensagem(
                f"Buscar todas as informa√ß√µes sobre {topico}",
                self.contexto_atual
            )

        # ===== FASE 2: GERA√á√ÉO DE IDEIAS =====
        # Solicita ideias criativas e inovadoras sobre o t√≥pico
        if self.agente_brainstorm:
            resultados["analises"]["ideias"] = self.agente_brainstorm.processar_mensagem(
                f"Gerar ideias criativas para {topico}",
                self.contexto_atual
            )

        # ===== FASE 3: AN√ÅLISE DE DADOS =====
        # Analisa padr√µes, tend√™ncias e insights sobre o t√≥pico
        if self.agente_analise:
            resultados["analises"]["analise"] = self.agente_analise.processar_mensagem(
                f"Analisar padr√µes e tend√™ncias relacionados a {topico}",
                self.contexto_atual
            )

        # ===== FASE 4: CONSOLIDA√á√ÉO =====
        # Gera um resumo executivo consolidando todas as an√°lises
        resultados["resumo_executivo"] = self.gerar_resumo_executivo(topico, resultados["analises"])

        return resultados
    
    def limpar_historico_conversa(self):
        """Limpa o hist√≥rico da conversa atual"""
        self.historico_conversa_atual = []
        self.mensagens_vazias = 0

    def __repr__(self):
        # Conta quantos agentes especializados est√£o conectados
        agentes_conectados = sum(1 for a in [self.agente_consulta, self.agente_brainstorm, self.agente_analise] if a)
        return f"AgenteOrquestrador(agentes_conectados={agentes_conectados})"
