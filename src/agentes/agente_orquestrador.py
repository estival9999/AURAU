"""
Agente Orquestrador - O "maestro" do sistema AURALIS.
Interpreta inten√ß√µes, direciona para agentes especializados e coordena respostas.
"""

from typing import Dict, List, Any, Optional, Tuple
import json
import os
from enum import Enum

# Importar classe base apropriada
if os.getenv("OPENAI_API_KEY"):
    from .agente_base import AgenteBase
else:
    from .agente_base_simulado import AgenteBaseSimulado as AgenteBase

# Importar o novo sistema de templates
from .prompt_template import PromptTemplate, TomResposta


class TipoIntencao(Enum):
    """Tipos de inten√ß√£o que o orquestrador pode identificar.
    
    Cada tipo direciona para um agente especializado diferente.
    """
    CONSULTA = "CONSULTA"      # Busca de informa√ß√µes
    BRAINSTORM = "BRAINSTORM"  # Gera√ß√£o de ideias
    ANALISE = "ANALISE"        # An√°lise de dados
    GERAL = "GERAL"            # Consultas gerais
    MULTIPLA = "MULTIPLA"      # M√∫ltiplas inten√ß√µes


class AgenteOrquestrador(AgenteBase):
    """
    Agente respons√°vel por orquestrar o sistema AURALIS.
    
    Principais responsabilidades:
    - Interpretar inten√ß√µes do usu√°rio
    - Direcionar para agentes especializados
    - Coordenar respostas m√∫ltiplas
    - Manter contexto geral da conversa
    """
    
    def __init__(self):
        super().__init__(
            nome="Orquestrador AURALIS",
            descricao="Agente maestro que coordena e direciona as intera√ß√µes no sistema"
        )
        
        # ===== CONFIGURA√á√ÉO DO TEMPLATE =====
        # Usa o novo sistema de templates padronizados
        self.config_prompt = PromptTemplate.criar_config_orquestrador()
        
        # ===== MAPA DE AGENTES ESPECIALIZADOS =====
        # Mapeia cada tipo de inten√ß√£o para o nome do agente respons√°vel
        self.mapa_agentes = {
            TipoIntencao.CONSULTA: "Consultor Inteligente AURALIS",
            TipoIntencao.BRAINSTORM: "Agente Criativo AURALIS",
            TipoIntencao.ANALISE: "Analista AURALIS"
        }
        
        # ===== REFER√äNCIAS AOS AGENTES =====
        # Refer√™ncias diretas aos agentes especializados
        # Ser√£o definidas pelo sistema atrav√©s do m√©todo definir_agentes()
        self.agente_consulta = None
        self.agente_brainstorm = None
        self.agente_analise = None
        
        # ===== PALAVRAS-CHAVE PARA IDENTIFICA√á√ÉO =====
        # Dicion√°rio expandido com sin√¥nimos e varia√ß√µes
        self.palavras_chave = {
            TipoIntencao.CONSULTA: [
                # Verbos de busca
                "buscar", "encontrar", "procurar", "localizar", "pesquisar", "consultar",
                "verificar", "checar", "conferir", "identificar", "descobrir",
                # Pronomes interrogativos
                "quando", "onde", "quem", "qual", "quais", "quanto", "como", "porque",
                # Substantivos relacionados
                "reuni√£o", "reuni√µes", "meeting", "documento", "documentos", "arquivo",
                "hist√≥rico", "informa√ß√£o", "informa√ß√µes", "dado", "dados", "registro",
                # A√ß√µes de visualiza√ß√£o
                "listar", "mostrar", "exibir", "apresentar", "ver", "visualizar",
                # Contexto temporal
                "√∫ltima", "√∫ltimo", "anterior", "passada", "recente", "hoje", "ontem",
                "semana", "m√™s", "participou", "participaram", "decidiu", "decidido"
            ],
            TipoIntencao.BRAINSTORM: [
                # Substantivos criativos
                "ideia", "ideias", "sugest√£o", "sugest√µes", "proposta", "propostas",
                "solu√ß√£o", "solu√ß√µes", "alternativa", "alternativas", "op√ß√£o", "op√ß√µes",
                # Verbos de cria√ß√£o
                "criar", "gerar", "produzir", "desenvolver", "elaborar", "pensar",
                "imaginar", "inovar", "inventar", "conceber", "formular",
                # Termos de melhoria
                "melhorar", "aprimorar", "otimizar", "aperfei√ßoar", "evoluir",
                "transformar", "revolucionar", "mudar", "modificar",
                # Termos expl√≠citos
                "brainstorm", "brainstorming", "criativo", "criatividade", "inova√ß√£o",
                "inovador", "fora da caixa", "diferente", "novo", "original"
            ],
            TipoIntencao.ANALISE: [
                # Verbos anal√≠ticos
                "analisar", "examinar", "investigar", "estudar", "avaliar", "revisar",
                "comparar", "contrastar", "correlacionar", "diagnosticar",
                # Substantivos anal√≠ticos
                "an√°lise", "tend√™ncia", "tend√™ncias", "padr√£o", "padr√µes", "comportamento",
                "estat√≠stica", "estat√≠sticas", "m√©trica", "m√©tricas", "indicador",
                "indicadores", "kpi", "dashboard", "relat√≥rio", "gr√°fico",
                # Termos de insights
                "insight", "insights", "conclus√£o", "conclus√µes", "descoberta",
                "observa√ß√£o", "interpreta√ß√£o", "entendimento", "compreens√£o"
            ]
        }
        
        # ===== CONFIGURA√á√ïES DO MODELO =====
        # Usa configura√ß√µes do template
        self.temperatura = self.config_prompt.temperatura
        
    def get_prompt_sistema(self) -> str:
        """
        Define o prompt do sistema para o agente orquestrador.
        
        Returns:
            str: Prompt do sistema usando o template padronizado
        """
        # Usa o novo sistema de templates com contexto atual
        return PromptTemplate.gerar_prompt_contextualizado(
            self.config_prompt,
            self.contexto_atual
        )
    
    def identificar_intencao(self, mensagem: str) -> Tuple[TipoIntencao, float]:
        """
        Identifica a inten√ß√£o principal da mensagem do usu√°rio.
        
        Args:
            mensagem: Mensagem do usu√°rio
            
        Returns:
            Tuple[TipoIntencao, float]: Tipo de inten√ß√£o e score de confian√ßa
        """
        mensagem_lower = mensagem.lower()
        
        # ===== C√ÅLCULO DE SCORES =====
        # Calcula pontos para cada tipo de inten√ß√£o baseado nas palavras-chave encontradas
        scores = {}
        
        for tipo_intencao, palavras in self.palavras_chave.items():
            # Conta quantas palavras-chave est√£o presentes na mensagem
            score = sum(1 for palavra in palavras if palavra in mensagem_lower)
            scores[tipo_intencao] = score
        
        # Identificar inten√ß√£o com maior score
        max_score = max(scores.values())
        
        # Se nenhuma palavra-chave foi encontrada, classifica como consulta geral
        if max_score == 0:
            return TipoIntencao.GERAL, 0.5
        
        # ===== DETEC√á√ÉO DE M√öLTIPLAS INTEN√á√ïES =====
        # Verifica se h√° m√∫ltiplas inten√ß√µes com scores pr√≥ximos (70% do m√°ximo)
        intencoes_altas = [t for t, s in scores.items() if s >= max_score * 0.7 and s > 0]
        
        if len(intencoes_altas) > 1:
            return TipoIntencao.MULTIPLA, 0.8
        
        # Retornar a inten√ß√£o com maior score
        intencao_principal = max(scores, key=scores.get)
        # Normaliza a confian√ßa entre 0 e 1 (m√°ximo de 5 palavras-chave)
        confianca = min(scores[intencao_principal] / 5.0, 1.0)
        
        return intencao_principal, confianca
    
    def identificar_multiplas_intencoes(self, mensagem: str) -> List[TipoIntencao]:
        """
        Identifica m√∫ltiplas inten√ß√µes em uma mensagem.
        
        Args:
            mensagem: Mensagem do usu√°rio
            
        Returns:
            List[TipoIntencao]: Lista de inten√ß√µes identificadas
        """
        mensagem_lower = mensagem.lower()
        intencoes_encontradas = []
        
        for tipo_intencao, palavras in self.palavras_chave.items():
            if any(palavra in mensagem_lower for palavra in palavras):
                intencoes_encontradas.append(tipo_intencao)
        
        return intencoes_encontradas if intencoes_encontradas else [TipoIntencao.GERAL]
    
    def _verificar_casos_especiais(self, mensagem: str) -> Optional[str]:
        """
        Verifica casos especiais e erros comuns antes do processamento.
        
        Args:
            mensagem: Mensagem do usu√°rio
            
        Returns:
            Optional[str]: Resposta de erro se aplic√°vel, None caso contr√°rio
        """
        # ===== ENTRADA VAZIA =====
        if not mensagem or not mensagem.strip():
            return "Percebi que sua mensagem est√° vazia. Como posso ajudar voc√™ hoje? Voc√™ pode perguntar sobre reuni√µes passadas, pedir ideias criativas ou solicitar an√°lises."
        
        # ===== ENTRADA MUITO CURTA (poss√≠vel comando incompleto) =====
        mensagem_limpa = mensagem.strip().lower()
        if len(mensagem_limpa) < 3:
            comandos_sugeridos = {
                "?": "ajuda",
                "h": "hist√≥rico", 
                "b": "buscar",
                "i": "ideias"
            }
            
            if mensagem_limpa in comandos_sugeridos:
                return f"Voc√™ quis dizer '{comandos_sugeridos[mensagem_limpa]}'? Digite a palavra completa para eu entender melhor."
            
            return "Sua mensagem √© muito curta. Poderia elaborar um pouco mais? Por exemplo: 'Buscar reuni√µes sobre vendas' ou 'Ideias para melhorar produtividade'."
        
        # ===== ENTRADA MUITO LONGA =====
        if len(mensagem) > 1000:
            return ("Sua mensagem √© bastante detalhada. Vou processar os pontos principais. "
                   "Para melhores resultados, tente dividir solicita√ß√µes complexas em partes menores.")
        
        # ===== COMANDOS DE AJUDA =====
        if mensagem_limpa in ["ajuda", "help", "?", "o que voc√™ faz", "o que voce faz", "comandos"]:
            return self._gerar_mensagem_ajuda()
        
        # ===== SAUDA√á√ïES =====
        saudacoes = ["oi", "ol√°", "ola", "bom dia", "boa tarde", "boa noite", "hey", "ei"]
        if mensagem_limpa in saudacoes:
            return ("Ol√°! üëã Sou o Orquestrador do sistema AURALIS. "
                   "Como posso ajudar voc√™ hoje? Posso buscar informa√ß√µes de reuni√µes, "
                   "gerar ideias criativas ou analisar dados para voc√™.")
        
        return None  # Nenhum caso especial detectado
    
    def _gerar_mensagem_ajuda(self) -> str:
        """
        Gera mensagem de ajuda detalhada.
        
        Returns:
            str: Mensagem de ajuda formatada
        """
        return """ü§ñ **Bem-vindo ao Sistema AURALIS!**

Sou o Orquestrador e posso ajudar voc√™ com:

üìÖ **Consultas e Buscas:**
‚Ä¢ "Encontre reuni√µes sobre [t√≥pico]"
‚Ä¢ "Quem participou da reuni√£o de [data]?"
‚Ä¢ "Quais decis√µes foram tomadas sobre [projeto]?"
‚Ä¢ "Mostre documentos relacionados a [assunto]"

üí° **Gera√ß√£o de Ideias (Brainstorm):**
‚Ä¢ "Preciso de ideias para [desafio]"
‚Ä¢ "Como posso melhorar [processo]?"
‚Ä¢ "Sugest√µes criativas para [objetivo]"
‚Ä¢ "Alternativas para resolver [problema]"

üìä **An√°lises e Insights:**
‚Ä¢ "Analise as tend√™ncias de [m√©trica]"
‚Ä¢ "Compare resultados de [per√≠odo]"
‚Ä¢ "Identifique padr√µes em [dados]"
‚Ä¢ "Gere relat√≥rio sobre [t√≥pico]"

üí¨ **Dicas para melhores resultados:**
‚Ä¢ Seja espec√≠fico: inclua nomes, datas ou projetos
‚Ä¢ Para m√∫ltiplas perguntas, separe claramente cada uma
‚Ä¢ Use palavras-chave relevantes ao seu contexto

Como posso ajudar voc√™ agora?"""
    
    def processar_mensagem(self, mensagem: str, contexto: Dict[str, Any] = None) -> str:
        """
        Processa a mensagem do usu√°rio e orquestra a resposta.
        
        Args:
            mensagem: Mensagem do usu√°rio
            contexto: Contexto adicional
            
        Returns:
            str: Resposta orquestrada
        """
        # Atualizar contexto
        if contexto:
            self.atualizar_contexto(contexto)
        
        # ===== VALIDA√á√ïES E CASOS ESPECIAIS =====
        # Verifica casos de erro antes de processar
        resposta_erro = self._verificar_casos_especiais(mensagem)
        if resposta_erro:
            return resposta_erro
        
        # Identificar inten√ß√£o
        intencao, confianca = self.identificar_intencao(mensagem)
        
        # Log para depura√ß√£o - mostra a inten√ß√£o identificada
        print(f"[ORQUESTRADOR] Inten√ß√£o identificada: {intencao.value} (confian√ßa: {confianca:.2f})")
        
        # ===== PROCESSAMENTO BASEADO NA INTEN√á√ÉO =====
        if intencao == TipoIntencao.MULTIPLA:
            # Identifica e processa cada inten√ß√£o separadamente
            intencoes = self.identificar_multiplas_intencoes(mensagem)
            resposta = self._processar_multiplas_intencoes(mensagem, intencoes, contexto)
            
        elif intencao == TipoIntencao.GERAL:
            # Responder diretamente
            resposta = self._processar_consulta_geral(mensagem, contexto)
            
        else:
            # Delegar para agente espec√≠fico
            resposta = self._delegar_para_agente(mensagem, intencao, contexto)
        
        # Adicionar ao hist√≥rico
        self.adicionar_ao_historico(mensagem, resposta)
        
        return resposta
    
    def _processar_multiplas_intencoes(self, mensagem: str, intencoes: List[TipoIntencao], 
                                     contexto: Dict[str, Any]) -> str:
        """
        Processa m√∫ltiplas inten√ß√µes coordenando v√°rios agentes.
        
        Args:
            mensagem: Mensagem original
            intencoes: Lista de inten√ß√µes identificadas
            contexto: Contexto da conversa
            
        Returns:
            str: Resposta consolidada
        """
        respostas = []
        
        # Mensagem introdut√≥ria para o usu√°rio
        respostas.append("Identifiquei m√∫ltiplos aspectos na sua solicita√ß√£o. Vou abordar cada um:\n")
        
        # ===== PROCESSAMENTO DE CADA INTEN√á√ÉO =====
        for i, intencao in enumerate(intencoes, 1):
            # Pula inten√ß√µes gerais (j√° processadas)
            if intencao == TipoIntencao.GERAL:
                continue
                
            # Adiciona subt√≠tulo formatado para cada se√ß√£o
            subtitulo = f"\n**{i}. {self._get_titulo_intencao(intencao)}**\n"
            respostas.append(subtitulo)
            
            # Delega para o agente especializado apropriado
            resposta_agente = self._delegar_para_agente(mensagem, intencao, contexto)
            respostas.append(resposta_agente)
        
        return "\n".join(respostas)
    
    def _delegar_para_agente(self, mensagem: str, intencao: TipoIntencao, 
                           contexto: Dict[str, Any]) -> str:
        """
        Delega a mensagem para o agente especializado apropriado.
        
        Args:
            mensagem: Mensagem para processar
            intencao: Tipo de inten√ß√£o identificada
            contexto: Contexto da conversa
            
        Returns:
            str: Resposta do agente especializado
        """
        # ===== DELEGA√á√ÉO PARA AGENTES ESPECIALIZADOS =====
        # Verifica se temos refer√™ncia direta ao agente apropriado
        if intencao == TipoIntencao.CONSULTA and self.agente_consulta:
            return self.agente_consulta.processar_mensagem(mensagem, contexto)
            
        elif intencao == TipoIntencao.BRAINSTORM and self.agente_brainstorm:
            return self.agente_brainstorm.processar_mensagem(mensagem, contexto)
            
        elif intencao == TipoIntencao.ANALISE and self.agente_analise:
            # Se n√£o temos agente de an√°lise espec√≠fico, usa o de consulta
            agente = self.agente_analise or self.agente_consulta
            if agente:
                return agente.processar_mensagem(mensagem, contexto)
        
        # Fallback: se n√£o h√° agente dispon√≠vel, processa localmente
        return self._processar_localmente(mensagem, intencao, contexto)
    
    def _processar_localmente(self, mensagem: str, intencao: TipoIntencao, 
                            contexto: Dict[str, Any]) -> str:
        """
        Processa a mensagem localmente quando n√£o h√° agente especializado dispon√≠vel.
        
        Args:
            mensagem: Mensagem para processar
            intencao: Tipo de inten√ß√£o
            contexto: Contexto da conversa
            
        Returns:
            str: Resposta processada localmente
        """
        # Prepara prompt espec√≠fico para processamento local
        prompt = f"""Como Orquestrador do AURALIS, processe esta solicita√ß√£o de tipo {intencao.value}:

Mensagem do usu√°rio: {mensagem}

Contexto dispon√≠vel:
{self.formatar_contexto(contexto)}

Forne√ßa uma resposta apropriada, clara e profissional."""
        
        # Chama o modelo de linguagem para processar a solicita√ß√£o
        resposta = self.chamar_llm(prompt)
        
        return resposta
    
    def _processar_consulta_geral(self, mensagem: str, contexto: Dict[str, Any]) -> str:
        """
        Processa consultas gerais que o orquestrador pode responder diretamente.
        
        Args:
            mensagem: Mensagem do usu√°rio
            contexto: Contexto da conversa
            
        Returns:
            str: Resposta direta
        """
        prompt = f"""Como Orquestrador do AURALIS, responda diretamente esta consulta geral:

Mensagem: {mensagem}

Contexto:
{self.formatar_contexto(contexto)}

Seja claro, conciso e profissional."""
        
        return self.chamar_llm(prompt)
    
    def _get_titulo_intencao(self, intencao: TipoIntencao) -> str:
        """
        Retorna um t√≠tulo amig√°vel para cada tipo de inten√ß√£o.
        
        Args:
            intencao: Tipo de inten√ß√£o
            
        Returns:
            str: T√≠tulo formatado
        """
        titulos = {
            TipoIntencao.CONSULTA: "Busca de Informa√ß√µes",
            TipoIntencao.BRAINSTORM: "Gera√ß√£o de Ideias",
            TipoIntencao.ANALISE: "An√°lise de Dados",
            TipoIntencao.GERAL: "Informa√ß√µes Gerais"
        }
        return titulos.get(intencao, "Processamento")
    
    def definir_agentes(self, agente_consulta=None, agente_brainstorm=None, agente_analise=None):
        """
        Define as refer√™ncias diretas aos agentes especializados.
        
        Args:
            agente_consulta: Inst√¢ncia do agente de consulta
            agente_brainstorm: Inst√¢ncia do agente de brainstorm
            agente_analise: Inst√¢ncia do agente de an√°lise
        """
        if agente_consulta:
            self.agente_consulta = agente_consulta
        if agente_brainstorm:
            self.agente_brainstorm = agente_brainstorm
        if agente_analise:
            self.agente_analise = agente_analise
    
    def gerar_resumo_executivo(self, topico: str, informacoes: Dict[str, Any]) -> str:
        """
        Gera um resumo executivo consolidando informa√ß√µes de m√∫ltiplas fontes.
        
        Args:
            topico: T√≥pico do resumo
            informacoes: Dicion√°rio com informa√ß√µes de diferentes agentes
            
        Returns:
            str: Resumo executivo formatado
        """
        prompt = f"""Gere um resumo executivo profissional sobre: {topico}

Informa√ß√µes dispon√≠veis:
{json.dumps(informacoes, ensure_ascii=False, indent=2)}

O resumo deve incluir:
1. Vis√£o geral (2-3 linhas)
2. Principais pontos identificados
3. Recomenda√ß√µes baseadas nas an√°lises
4. Pr√≥ximos passos sugeridos

Formato profissional e conciso."""
        
        return self.chamar_llm(prompt)
    
    def coordenar_analise_completa(self, topico: str) -> Dict[str, Any]:
        """
        Coordena uma an√°lise completa usando todos os agentes dispon√≠veis.
        
        Args:
            topico: T√≥pico para an√°lise completa
            
        Returns:
            Dict: Resultados consolidados de todos os agentes
        """
        resultados = {
            "topico": topico,
            "timestamp": self.contexto_atual.get("timestamp", ""),
            "analises": {}
        }
        
        # ===== FASE 1: CONSULTA DE INFORMA√á√ïES =====
        # Busca todas as informa√ß√µes existentes sobre o t√≥pico
        if self.agente_consulta:
            resultados["analises"]["informacoes"] = self.agente_consulta.processar_mensagem(
                f"Buscar todas as informa√ß√µes sobre {topico}",
                self.contexto_atual
            )
        
        # ===== FASE 2: GERA√á√ÉO DE IDEIAS =====
        # Solicita ideias criativas e inovadoras sobre o t√≥pico
        if self.agente_brainstorm:
            resultados["analises"]["ideias"] = self.agente_brainstorm.processar_mensagem(
                f"Gerar ideias criativas para {topico}",
                self.contexto_atual
            )
        
        # ===== FASE 3: AN√ÅLISE DE DADOS =====
        # Analisa padr√µes, tend√™ncias e insights sobre o t√≥pico
        if self.agente_analise:
            resultados["analises"]["analise"] = self.agente_analise.processar_mensagem(
                f"Analisar padr√µes e tend√™ncias relacionados a {topico}",
                self.contexto_atual
            )
        
        # ===== FASE 4: CONSOLIDA√á√ÉO =====
        # Gera um resumo executivo consolidando todas as an√°lises
        resultados["resumo_executivo"] = self.gerar_resumo_executivo(topico, resultados["analises"])
        
        return resultados
    
    def __repr__(self):
        # Conta quantos agentes especializados est√£o conectados
        agentes_conectados = sum(1 for a in [self.agente_consulta, self.agente_brainstorm, self.agente_analise] if a)
        return f"AgenteOrquestrador(agentes_conectados={agentes_conectados})"